{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a New Elvis Presley Song Lyric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reading the dataset into a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text  \n",
       "0  Look at her face, it's a wonderful face  \\nAnd...  \n",
       "1  Take it easy with me, please  \\nTouch me gentl...  \n",
       "2  I'll never know why I had to go  \\nWhy I had t...  \n",
       "3  Making somebody happy is a question of give an...  \n",
       "4  Making somebody happy is a question of give an...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('songdata.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get all the songs for Elvis Presley from the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>Elvis Presley</td>\n",
       "      <td>A Big Hunk O' Love</td>\n",
       "      <td>/e/elvis+presley/a+big+hunk+o+love_20048096.html</td>\n",
       "      <td>Hey baby, I ain't askin' much of you  \\nNo no ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>Elvis Presley</td>\n",
       "      <td>A Boy Like Me, A Girl Like You</td>\n",
       "      <td>/e/elvis+presley/a+boy+like+me+a+girl+like+you...</td>\n",
       "      <td>When a boy like me meets a girl like you  \\nTh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>Elvis Presley</td>\n",
       "      <td>A Fool Such As I</td>\n",
       "      <td>/e/elvis+presley/a+fool+such+as+i_10104893.html</td>\n",
       "      <td>Now and then, there's a fool such as I  \\nPard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003</th>\n",
       "      <td>Elvis Presley</td>\n",
       "      <td>A Whistling Tune</td>\n",
       "      <td>/e/elvis+presley/a+whistling+tune_20047916.html</td>\n",
       "      <td>Did you ever notice when the sun goes down  \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>Elvis Presley</td>\n",
       "      <td>After Loving You</td>\n",
       "      <td>/e/elvis+presley/after+loving+you_20047783.html</td>\n",
       "      <td>But now after loving you, what else is there t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             artist                            song  \\\n",
       "5000  Elvis Presley              A Big Hunk O' Love   \n",
       "5001  Elvis Presley  A Boy Like Me, A Girl Like You   \n",
       "5002  Elvis Presley                A Fool Such As I   \n",
       "5003  Elvis Presley                A Whistling Tune   \n",
       "5004  Elvis Presley                After Loving You   \n",
       "\n",
       "                                                   link  \\\n",
       "5000   /e/elvis+presley/a+big+hunk+o+love_20048096.html   \n",
       "5001  /e/elvis+presley/a+boy+like+me+a+girl+like+you...   \n",
       "5002    /e/elvis+presley/a+fool+such+as+i_10104893.html   \n",
       "5003    /e/elvis+presley/a+whistling+tune_20047916.html   \n",
       "5004    /e/elvis+presley/after+loving+you_20047783.html   \n",
       "\n",
       "                                                   text  \n",
       "5000  Hey baby, I ain't askin' much of you  \\nNo no ...  \n",
       "5001  When a boy like me meets a girl like you  \\nTh...  \n",
       "5002  Now and then, there's a fool such as I  \\nPard...  \n",
       "5003  Did you ever notice when the sun goes down  \\n...  \n",
       "5004  But now after loving you, what else is there t...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elvis = df[df['artist'] == 'Elvis Presley']\n",
    "elvis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hey baby, I ain't askin' much of you  \\nNo no no no no no no no  \\nBaby, I ain't askin' much of you  \\nJust a big a big a big a hunk o' love will do  \\n  \\nDon't be a stingy little mama  \\nYou're 'bout to starve me half to death  \\nNow you can spare a kiss or two  \\nAnd still have plenty left  \\n  \\nOh no no baby  \\nI ain't askin' much of you  \\nJust a big a big a big a hunk o' love will do  \\nThat's right  \\n  \\nYou're just a natural born beehive  \\nFilled with honey to the top  \\nBut I ain't greedy baby  \\nAll I want is all you got  \\n  \\nOh no no  \\nBaby, I ain't askin' much of you  \\nJust a big a big a big a hunk o' love will do  \\nThat's right  \\n  \\nI got a wishbone in my pocket  \\nI got a rabbit foot around my wrist  \\nI'd have all of the things my lucky charms could bring  \\nIf you give me just a one sweet kiss  \\n  \\nOh no no no no no no no no  \\nBaby, I ain't askin' much of you  \\nJust a big a hunk o' hunk o' hunk o' love will do  \\nJust a big a big a big a hunk o' love will do  \\nJust a big a big a big a hunk o' love will do\\n\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs = elvis['text'].values\n",
    "songs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------\n",
      "Come back, baby, I want to play house with you.\n",
      "Come back, baby, come.\n",
      "Now baby, Come back, baby, come.\n",
      "Ain't that loving you baby?\n",
      "Hey!\n",
      "I don't want no other love, Baby it's just you I'm thinking of.\n",
      "Didja' ever get one of them days, boy?\n",
      "Baby, baby baby, be-be-be-be-be-be baby baby, baby.\n",
      "Baby baby baby be-be-be-be-be-be baby baby baby.\n",
      "Baby baby baby Come back, baby, I want to play house with you.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import heapq\n",
    "\n",
    "text = \"\"\n",
    "for song in songs:\n",
    "    text += song\n",
    "text = re.sub(r'\\[[0-9]*\\]',' ',text)\n",
    "text = re.sub(r'\\s+',' ',text)\n",
    "\n",
    "clean_text = text.lower()\n",
    "clean_text = re.sub(r'\\W',' ',clean_text)\n",
    "clean_text = re.sub(r'\\d',' ',clean_text)\n",
    "clean_text = re.sub(r'\\s+',' ',clean_text)\n",
    "\n",
    "# Tokenize sentences\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "# Stopword list\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "\n",
    "# Word counts \n",
    "word2count = {}\n",
    "for word in nltk.word_tokenize(clean_text):\n",
    "    if word not in stop_words:\n",
    "        if word not in word2count.keys():\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1\n",
    "            \n",
    "\n",
    "#Converting counts to weights\n",
    "maxi = max(word2count.values())\n",
    "for key in word2count.keys():\n",
    "    word2count[key] = word2count[key]/maxi\n",
    "    \n",
    "\n",
    "# Product sentence scores    \n",
    "sent2score = {}\n",
    "for sentence in sentences:\n",
    "    for word in nltk.word_tokenize(sentence.lower()):\n",
    "        if word in word2count.keys():\n",
    "            if len(sentence.split(' ')) < 15:\n",
    "                if sentence not in sent2score.keys():\n",
    "                    sent2score[sentence] = word2count[word]\n",
    "                else:\n",
    "                    sent2score[sentence] += word2count[word]\n",
    "                    \n",
    "\n",
    "#Gettings best 10 lines             \n",
    "best_sentences = heapq.nlargest(10, sent2score, key=sent2score.get)\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "for sentence in best_sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########################################################################################\n",
    "\n",
    "# Summarization With Textrank Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm a fool but I'll love you dear until the day I die  \n",
      "I'm a fool but I'll love you dear until the day I die  \n",
      "Some day I know, she'll come back again to me  \n",
      "Some day I know, she'll come back again to me  \n",
      "When that time comes you'll know who I am  \n",
      "When that time comes you'll know who I am  \n",
      "When that time comes you'll know who I am\n",
      "I'll go on loving you  \n",
      "Well, tonight she'll know I'm a mighty, mighty man  \n",
      "Well, tonight she'll know I'm a mighty, mighty man  \n"
     ]
    }
   ],
   "source": [
    "from summa import summarizer\n",
    "text = \"\"\n",
    "for song in songs:\n",
    "    text += song\n",
    "\n",
    "summary = summarizer.summarize(text, words=100)\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ali\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Come back, baby, I want to play house with you.\n",
      "Come back, baby, I want to play house with you.\n",
      "Come back, baby, I want to play house with you.\n",
      "You know you ain't so big, I said you're just tall that's all, All right  \n",
      "Love like ours remains divine, come what may  \n",
      "Could I fall in love on a night like tonight  \n",
      "Strong enough to rule the heart of every man, this thing called love  \n",
      "Like I loved you, and baby I still do  \n",
      "I really love you baby, cross my heart.\n",
      "This time of evening my love comes down  \n"
     ]
    }
   ],
   "source": [
    "import gensim.summarization\n",
    "\n",
    "summary = gensim.summarization.summarize(text, word_count=100)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_array = []\n",
    "for song in songs:\n",
    "    token = nltk.sent_tokenize(song)\n",
    "    token = song.split('\\n')\n",
    "    sentences_array.append(token)\n",
    "\n",
    "sentences = []\n",
    "for sent in sentences_array:\n",
    "    sentences.append(sent[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    \"\"\"\n",
    "    clean a given text\n",
    "    \"\"\"\n",
    "    clean_text = text.lower()\n",
    "    clean_text = re.sub(r'\\W',' ',clean_text)\n",
    "    clean_text = re.sub(r'\\d',' ',clean_text)\n",
    "    clean_text = re.sub(r'\\s+',' ',clean_text)\n",
    "    return clean_text\n",
    "\n",
    "clean_sentences = []\n",
    "for s in sentences:\n",
    "    clean_sentence = clean(s)\n",
    "    if len(clean_sentence) < 2: # if it is less than 2, it may just contain empty space\n",
    "        continue\n",
    "    clean_sentences.append(clean_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "\n",
    "def remove_stopwords(sentence):\n",
    "    \"\"\"\n",
    "    remove stop words from a given sentence\n",
    "    \"\"\"\n",
    "    new_sentence = \" \".join([i for i in sentence if i not in stop_words])\n",
    "    return new_sentence\n",
    "clean_sentences = [remove_stopwords(s.split()) for s in clean_sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def similarity(s1, s2):\n",
    "    \"\"\"\n",
    "    calculate the similarity between two sentences\n",
    "    \"\"\"\n",
    "    s1_words = s1.split()\n",
    "    s2_words = s2.split()\n",
    "    sim = len([w for w in set(s1_words) if w in set(s2_words)]) \n",
    "    log_s1 = math.log10(len(s1_words))\n",
    "    log_s2 = math.log10(len(s2_words))\n",
    "    if log_s1 + log_s2 == 0:\n",
    "        return 0\n",
    "    return sim / (log_s1 + log_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# initialize the similarity matrix with zeros\n",
    "sim_Matrix = np.zeros([len(clean_sentences), len(clean_sentences)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(clean_sentences)):\n",
    "    for j in range(len(clean_sentences)):\n",
    "        if i != j:\n",
    "            s1 = clean_sentences[i]\n",
    "            s2 = clean_sentences[j]\n",
    "            # check if length of the sentence is bigger than 1 because some sentences just have empty space\n",
    "            if len(s1) < 2 or len(s2) < 2:\n",
    "                continue\n",
    "            sim_Matrix[i][j] = similarity(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# get graph from the similarity matrix\n",
    "G = nx.from_numpy_array(sim_Matrix)\n",
    "\n",
    "# apply the pagerank algorithm\n",
    "pr = nx.pagerank(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_sentences = sorted(((pr[i],sentence) for i,sentence in enumerate(clean_sentences)), reverse= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baby know well\n",
      "oh yes know true\n",
      "never know much love\n",
      "well since baby left\n",
      "said take easy baby\n",
      "guys fall love one girl gotta fall two\n",
      "put red dress baby cause going tonight oh yeah\n",
      "know\n",
      "fools fall love hurry\n",
      "sincere say love\n"
     ]
    }
   ],
   "source": [
    "#Extract top 10 sentences as the summary\n",
    "for i in range(10):\n",
    "    print(ranked_sentences[i][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
